{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# iPRG 2016 Study on proteoform determination\n",
      "\n",
      "## Introduction\n",
      "This is an Jupyther Notebook. Jupyther is a format for combining text and python code into documents, that encourages interaction with the code. For more details on using Jupyther Notebook see http://jupyter.readthedocs.io.\n",
      "\n",
      "The following is a template and step-by-step example solution of the 2016 iPRG study as well as an example for how to submit and share such solutions in a Jupyter Notebook.\n",
      "\n",
      "Participants are free to analyze the data in any way they see fit, using either or both MS1 and MS2 data, as long as the results are presented in a data matrix of the format, row and column names as defined below. In this example, we use [Crux](http://cruxtoolkit.sourceforge.net/). This is not an endorsement or recommendation to use this particular software. Partipants are also allowed to submit their results in a spreadsheet, as in previous studies, or as a Python script.\n",
      "\n",
      "In iPRG studies, it is important all participants start from the same data and use the sequence databases provided by the iPRG. The raw data files are included in the study package that can be downloaded from iprg2016.org.\n",
      "\n",
      "## Helper scripts\n",
      "\n",
      "First we create some functions that we can use in the processing. First a script for reading the protein names from FASTA-files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def getAllProteinNames(fastaFile):\n",
      "    proteinNames = []\n",
      "    with open(fastaFile,\"r\") as lines:\n",
      "        for line in lines:\n",
      "            if line[0]=='>':\n",
      "                line = line[1:]\n",
      "                line = line.rstrip()\n",
      "                words = line.split(' ')\n",
      "                proteinNames.append(words[0])\n",
      "    return proteinNames"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need a function to parse crux-percolator peptide list into lists of proteins according to the two-peptide rule. Here, we count any protein mentioned two times, regardless of how many homologs there are for each peptide. We recognize that this is not an optimal protein inference strategy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "def parsePeptieFileUsingTwoPeptidesRule(fileName, isDecoy):\n",
      "    with open(fileName, \"r\") as fileIter:\n",
      "        tabReader = csv.reader(fileIter,doublequote = False, delimiter = '\\t')\n",
      "        colNames = tabReader.next()\n",
      "        proteinsCol=colNames.index(\"protein id\")\n",
      "        scoreCol=colNames.index(\"percolator score\")\n",
      "        lowNumber = -0.4711e10\n",
      "        proteinDict = dict()\n",
      "        for row in tabReader:\n",
      "            proteins = row[proteinsCol]\n",
      "            score = row[scoreCol]\n",
      "            for protein in proteins.split(','):\n",
      "                if protein in proteinDict:\n",
      "                    if proteinDict[protein] == lowNumber:\n",
      "                        # assign the score of the second best scoring peptide to the protein\n",
      "                        proteinDict[protein] = score\n",
      "                else:\n",
      "                    proteinDict[protein] = lowNumber\n",
      "    proteinList = []\n",
      "    for prot in proteinDict:\n",
      "        if proteinDict[prot] != lowNumber:\n",
      "            proteinList.append((proteinDict[prot],isDecoy,prot))\n",
      "    return proteinList\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And a function that can calculate a primitive FDR, given lists of target and decoy proteins. We recognize again that this might not be an optimal choice of FDR calculation procedure."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getProteinWithFDR(targetFile,decoyFile):\n",
      "    proteins = parsePeptieFileUsingTwoPeptidesRule(targetFile,False)\n",
      "    proteins += parsePeptieFileUsingTwoPeptidesRule(decoyFile,True)\n",
      "    proteins.sort(reverse=True, key=lambda prot_tupple: prot_tupple[0])\n",
      "    protFdrDict = dict()\n",
      "    targets,decoys = 0,0\n",
      "    order = []\n",
      "    search = True\n",
      "    for score,isDecoy,prot in proteins:\n",
      "        if isDecoy:\n",
      "            decoys += 1\n",
      "        else:\n",
      "            targets += 1\n",
      "            fdr = decoys/float(targets)\n",
      "            protFdrDict[prot] = fdr\n",
      "            order.append(prot)\n",
      "            if (search and fdr>0.01):\n",
      "                print \"Found %d proteins at FDR %f\"%(targets,fdr)\n",
      "                search = False\n",
      "    order.reverse()\n",
      "    # Set the q value to be the minimal FDR that includes the current protein\n",
      "    q=1.0\n",
      "    for prot in order:\n",
      "        q = min(q,protFdrDict[prot])\n",
      "        protFdrDict[prot] = q\n",
      "    return protFdrDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Processing of files\n",
      "\n",
      "So now lets get down to the actual processing.  \n",
      "We first need to convert our raw files into mzMLs. We do so using ProteoWizard's msconvert. Unfortunately this does not work under non-Windows platforms, so if you ar running the notebook under Linux or OS-X, just skip this stage, and download the mzML files directly from the [iPRG site](http://iprg2016.org/). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import subprocess\n",
      "import glob\n",
      "\n",
      "for raw_file in glob.glob(\"*.raw\"):\n",
      "    if not os.path.isfile(os.path.splitext(raw_file)[0]+\".mzML\"):\n",
      "        msconvert_call = 'msconvert %s --32 --zlib --filter \\\"peakPicking true 2-\\\" --filter \\\"msLevel 2\\\"'% raw_file\n",
      "        subprocess.call(msconvert_call)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we are runing on linux or OS-X this is the first point of prcessing.  \n",
      "\n",
      "Here, we match our spectra to the provided protein sequence database. We first convert the fasta to an index, that we then use for the Tide matching procedure. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fastaFile = \"iPRG2016.fasta\"\n",
      "spec_files = glob.glob(\"*.mzML\")\n",
      "setNames=[os.path.splitext(fileName)[0] for fileName in spec_files]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "import glob\n",
      "import sys\n",
      "\n",
      "\n",
      "subprocess.call([\"crux\", \"tide-index\", \n",
      "      fastaFile, \"prest-index\"])\n",
      "\n",
      "for setN in setNames:\n",
      "    options = \"--output-dir %s-output --overwrite T --compute-sp T --overwrite T --precursor-window 5.0 --precursor-window-type ppm\" % setN  \n",
      "    tide_call = \"crux tide-search %s %s.mzML prest-index\" % (options,setN) \n",
      "    print \"Matching %s.mzML against the amino acid sequences.\"%(setN)\n",
      "    subprocess.check_output(tide_call,  shell=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We postprocessing the results with percolator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for setN in setNames:\n",
      "    print \"Post processing %s\\'s results.\"%(setN)\n",
      "    options = \"--output-dir %s-output --overwrite T\" % setN  \n",
      "    percolator_call = \"crux percolator %s ./%s-output/tide-search.target.txt\" % (options,setN)\n",
      "\n",
      "    subprocess.check_output(percolator_call, shell=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And parse the results into one dctionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proteinRunDict = dict()\n",
      "for prot in getAllProteinNames(fastaFile):\n",
      "    # Only report the PrEST sequences\n",
      "    if prot[:4]=='HPRR':\n",
      "        proteinRunDict[prot] = []\n",
      "\n",
      "for setN in setNames:\n",
      "    print \"Parsing %s\\'s results.\"%(setN)\n",
      "    protFdrDict = getProteinWithFDR(\"%s-output/percolator.target.peptides.txt\"%(setN),\n",
      "                    \"%s-output/percolator.decoy.peptides.txt\"%(setN))\n",
      "    for prot in proteinRunDict:\n",
      "        if prot in protFdrDict:\n",
      "            fdr = protFdrDict[prot]\n",
      "        else:\n",
      "            fdr = float(1.0)\n",
      "        proteinRunDict[prot].append(fdr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we write the FDRs into a tab-delimited result file. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "\n",
      "with open(\"my_resultFile.txt\",\"w\") as outFile:\n",
      "    csvWriter = csv.writer(outFile, delimiter = '\\t',quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
      "    csvWriter.writerow([\"FDR\"]+setNames)\n",
      "    for prot in proteinRunDict:\n",
      "        csvWriter.writerow([prot]+proteinRunDict[prot])\n",
      "    outFile.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}